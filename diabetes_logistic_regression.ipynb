{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa3c083",
   "metadata": {},
   "source": [
    "# Diabetes classification with logistic regression\n",
    "\n",
    "Predict whether a person has **any** type of diabetes (yes/no) using a basic logistic regression model trained with NumPy only.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f16824b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 253680 samples with 21 features\n",
      "Share of positive diabetes cases: 0.158\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Load raw CSV: first column is diabetes status (0/1/2), remaining columns are features\n",
    "DATA_PATH = Path(\"diabetes_012_health_indicators_BRFSS2015.csv\")\n",
    "\n",
    "raw = np.loadtxt(DATA_PATH, delimiter=\",\", skiprows=1)\n",
    "\n",
    "# Features and binary target (any non-zero diabetes -> 1, else 0)\n",
    "X = raw[:, 1:]\n",
    "y = (raw[:, 0] > 0).astype(np.float64)\n",
    "\n",
    "print(f\"Loaded {X.shape[0]} samples with {X.shape[1]} features\")\n",
    "print(f\"Share of positive diabetes cases: {y.mean():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34389566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 152208 | Val size: 50736 | Test size: 50736\n"
     ]
    }
   ],
   "source": [
    "# Train / validation / test split\n",
    "rng = np.random.default_rng(42)\n",
    "indices = np.arange(len(X))\n",
    "rng.shuffle(indices)\n",
    "\n",
    "n = len(indices)\n",
    "train_end = int(0.6 * n)\n",
    "val_end = int(0.8 * n)\n",
    "\n",
    "train_idx = indices[:train_end]\n",
    "val_idx = indices[train_end:val_end]\n",
    "test_idx = indices[val_end:]\n",
    "\n",
    "X_train, X_val, X_test = X[train_idx], X[val_idx], X[test_idx]\n",
    "y_train, y_val, y_test = y[train_idx], y[val_idx], y[test_idx]\n",
    "\n",
    "# Standardize features based on training set only\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "std[std == 0] = 1.0\n",
    "\n",
    "X_train = (X_train - mean) / std\n",
    "X_val = (X_val - mean) / std\n",
    "X_test = (X_test - mean) / std\n",
    "\n",
    "print(f\"Train size: {len(X_train)} | Val size: {len(X_val)} | Test size: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6080388",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionGD:\n",
    "    def __init__(self, lr=0.05, epochs=2000, reg=0.001):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.reg = reg\n",
    "        self.w = None\n",
    "        self.b = 0.0\n",
    "\n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y, verbose=False):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.w = np.zeros(n_features)\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            linear = X @ self.w + self.b\n",
    "            preds = self._sigmoid(linear)\n",
    "            error = preds - y\n",
    "\n",
    "            grad_w = (X.T @ error) / n_samples + self.reg * self.w\n",
    "            grad_b = error.mean()\n",
    "\n",
    "            self.w -= self.lr * grad_w\n",
    "            self.b -= self.lr * grad_b\n",
    "\n",
    "            if verbose and epoch % 500 == 0:\n",
    "                loss = -np.mean(\n",
    "                    y * np.log(preds + 1e-8) + (1 - y) * np.log(1 - preds + 1e-8)\n",
    "                )\n",
    "                print(f\"epoch {epoch:4d} | loss {loss:.4f}\")\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self._sigmoid(X @ self.w + self.b)\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        return (self.predict_proba(X) >= threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e094d253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for good hyperparameters (full grid)...\n",
      "\n",
      "lr=0.010, reg=0.00000, epochs=1000 -> val acc=0.8488\n",
      "lr=0.010, reg=0.00000, epochs=2000 -> val acc=0.8497\n",
      "lr=0.010, reg=0.00010, epochs=1000 -> val acc=0.8487\n",
      "lr=0.010, reg=0.00010, epochs=2000 -> val acc=0.8497\n",
      "lr=0.010, reg=0.00100, epochs=1000 -> val acc=0.8487\n",
      "lr=0.010, reg=0.00100, epochs=2000 -> val acc=0.8496\n",
      "lr=0.010, reg=0.01000, epochs=1000 -> val acc=0.8488\n",
      "lr=0.010, reg=0.01000, epochs=2000 -> val acc=0.8497\n",
      "lr=0.030, reg=0.00000, epochs=1000 -> val acc=0.8498\n",
      "lr=0.030, reg=0.00000, epochs=2000 -> val acc=0.8496\n",
      "lr=0.030, reg=0.00010, epochs=1000 -> val acc=0.8497\n",
      "lr=0.030, reg=0.00010, epochs=2000 -> val acc=0.8496\n",
      "lr=0.030, reg=0.00100, epochs=1000 -> val acc=0.8496\n",
      "lr=0.030, reg=0.00100, epochs=2000 -> val acc=0.8494\n",
      "lr=0.030, reg=0.01000, epochs=1000 -> val acc=0.8500\n",
      "lr=0.030, reg=0.01000, epochs=2000 -> val acc=0.8497\n",
      "lr=0.050, reg=0.00000, epochs=1000 -> val acc=0.8495\n",
      "lr=0.050, reg=0.00000, epochs=2000 -> val acc=0.8494\n",
      "lr=0.050, reg=0.00010, epochs=1000 -> val acc=0.8495\n",
      "lr=0.050, reg=0.00010, epochs=2000 -> val acc=0.8493\n",
      "lr=0.050, reg=0.00100, epochs=1000 -> val acc=0.8496\n",
      "lr=0.050, reg=0.00100, epochs=2000 -> val acc=0.8494\n",
      "lr=0.050, reg=0.01000, epochs=1000 -> val acc=0.8499\n",
      "lr=0.050, reg=0.01000, epochs=2000 -> val acc=0.8496\n",
      "lr=0.100, reg=0.00000, epochs=1000 -> val acc=0.8494\n",
      "lr=0.100, reg=0.00000, epochs=2000 -> val acc=0.8495\n",
      "lr=0.100, reg=0.00010, epochs=1000 -> val acc=0.8493\n",
      "lr=0.100, reg=0.00010, epochs=2000 -> val acc=0.8495\n",
      "lr=0.100, reg=0.00100, epochs=1000 -> val acc=0.8494\n",
      "lr=0.100, reg=0.00100, epochs=2000 -> val acc=0.8493\n",
      "lr=0.100, reg=0.01000, epochs=1000 -> val acc=0.8496\n",
      "lr=0.100, reg=0.01000, epochs=2000 -> val acc=0.8497\n",
      "\n",
      "Best hyperparameters (by validation accuracy):\n",
      "lr=0.030, reg=0.01000, epochs=1000\n",
      "Validation accuracy: 0.8500\n",
      "\n",
      "Best threshold on validation set: 0.500 (val acc=0.8500)\n",
      "\n",
      "Final model performance with tuned hyperparameters and threshold:\n",
      "\n",
      "Train accuracy : 0.848\n",
      "Train precision: 0.566\n",
      "Train recall   : 0.160\n",
      "\n",
      "Val accuracy : 0.850\n",
      "Val precision: 0.568\n",
      "Val recall   : 0.152\n",
      "\n",
      "Test accuracy : 0.847\n",
      "Test precision: 0.555\n",
      "Test recall   : 0.162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_split(name, y_true, y_pred):\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    tp = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    fp = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    fn = np.sum((y_pred == 0) & (y_true == 1))\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    print(f\"{name} accuracy : {acc:.3f}\")\n",
    "    print(f\"{name} precision: {precision:.3f}\")\n",
    "    print(f\"{name} recall   : {recall:.3f}\\n\")\n",
    "\n",
    "\n",
    "# Grid search over a few basic hyperparameters using validation accuracy\n",
    "learning_rates = [0.01, 0.03, 0.05, 0.1]\n",
    "regs = [0.0, 0.0001, 0.001, 0.01]\n",
    "epochs_list = [1000, 2000]\n",
    "\n",
    "best_val_acc = -1.0\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(\"Searching for good hyperparameters (full grid)...\\n\")\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for reg in regs:\n",
    "        for epochs in epochs_list:\n",
    "            model = LogisticRegressionGD(lr=lr, reg=reg, epochs=epochs)\n",
    "            model.fit(X_train, y_train, verbose=False)\n",
    "\n",
    "            val_preds = model.predict(X_val)\n",
    "            val_acc = (val_preds == y_val).mean()\n",
    "\n",
    "            print(f\"lr={lr:.3f}, reg={reg:.5f}, epochs={epochs} -> val acc={val_acc:.4f}\")\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_params = (lr, reg, epochs)\n",
    "                best_model = model\n",
    "\n",
    "print(\"\\nBest hyperparameters (by validation accuracy):\")\n",
    "print(f\"lr={best_params[0]:.3f}, reg={best_params[1]:.5f}, epochs={best_params[2]}\")\n",
    "print(f\"Validation accuracy: {best_val_acc:.4f}\\n\")\n",
    "\n",
    "# Tune decision threshold on the validation set for best accuracy\n",
    "val_proba = best_model.predict_proba(X_val)\n",
    "thresholds = np.linspace(0.3, 0.7, 41)\n",
    "\n",
    "best_thresh = 0.5\n",
    "best_thresh_acc = -1.0\n",
    "\n",
    "for t in thresholds:\n",
    "    preds_t = (val_proba >= t).astype(int)\n",
    "    acc_t = (preds_t == y_val).mean()\n",
    "    if acc_t > best_thresh_acc:\n",
    "        best_thresh_acc = acc_t\n",
    "        best_thresh = t\n",
    "\n",
    "print(f\"Best threshold on validation set: {best_thresh:.3f} (val acc={best_thresh_acc:.4f})\\n\")\n",
    "\n",
    "# Evaluate final model on train, val, and test using tuned threshold\n",
    "print(\"Final model performance with tuned hyperparameters and threshold:\\n\")\n",
    "\n",
    "train_preds = best_model.predict(X_train, threshold=best_thresh)\n",
    "val_preds = best_model.predict(X_val, threshold=best_thresh)\n",
    "test_preds = best_model.predict(X_test, threshold=best_thresh)\n",
    "\n",
    "evaluate_split(\"Train\", y_train, train_preds)\n",
    "evaluate_split(\"Val\", y_val, val_preds)\n",
    "evaluate_split(\"Test\", y_test, test_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd461b54-45cc-4aae-a5b7-3735d1136710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
