{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Diabetes classification with XGBoost\n",
        "\n",
        "Predict whether a person has **any** form of diabetes (prediabetes or diabetes) using gradient-boosted trees (XGBoost) on the BRFSS 2015 health indicators dataset.\n",
        "\n",
        "We follow the Phase II progress report methodology: merge prediabetes + diabetes into a single positive class, handle class imbalance, and evaluate using ROC-AUC, PR-AUC, recall, F1, and accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "DATA_PATH = Path(\"diabetes_012_health_indicators_BRFSS2015.csv\")\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "# Merge prediabetes (1) and diabetes (2) into one positive class\n",
        "df[\"Diabetes_binary\"] = (df[\"Diabetes_012\"] > 0).astype(int)\n",
        "\n",
        "feature_cols = [c for c in df.columns if c not in [\"Diabetes_012\", \"Diabetes_binary\"]]\n",
        "X = df[feature_cols].values\n",
        "y = df[\"Diabetes_binary\"].values\n",
        "\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(\"Class distribution (0=no diabetes, 1=any diabetes):\")\n",
        "unique, counts = np.unique(y, return_counts=True)\n",
        "for cls, cnt in zip(unique, counts):\n",
        "    print(f\"  class {cls}: {cnt} samples ({cnt / len(y):.3f} share)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stratified train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "# Compute scale_pos_weight for XGBoost (helps with class imbalance)\n",
        "neg, pos = np.bincount(y_train)\n",
        "scale_pos_weight = neg / pos\n",
        "\n",
        "print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
        "print(f\"Positive class fraction in train: {pos / (neg + pos):.3f}\")\n",
        "print(f\"scale_pos_weight for XGBoost: {scale_pos_weight:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(name, y_true, y_proba, threshold=0.5):\n",
        "    y_pred = (y_proba >= threshold).astype(int)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    roc = roc_auc_score(y_true, y_proba)\n",
        "    pr_auc = average_precision_score(y_true, y_proba)\n",
        "\n",
        "    print(f\"{name} metrics (threshold={threshold:.2f}):\")\n",
        "    print(f\"  Accuracy : {acc:.3f}\")\n",
        "    print(f\"  Precision: {prec:.3f}\")\n",
        "    print(f\"  Recall   : {rec:.3f}\")\n",
        "    print(f\"  F1-score : {f1:.3f}\")\n",
        "    print(f\"  ROC-AUC  : {roc:.3f}\")\n",
        "    print(f\"  PR-AUC   : {pr_auc:.3f}\\n\")\n",
        "\n",
        "    print(\"Confusion matrix (rows=true, cols=pred):\")\n",
        "    print(confusion_matrix(y_true, y_pred))\n",
        "    print(\"\\nClassification report:\")\n",
        "    print(classification_report(y_true, y_pred, digits=3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Base XGBoost classifier configuration\n",
        "base_params = dict(\n",
        "    objective=\"binary:logistic\",\n",
        "    tree_method=\"hist\",  # efficient for tabular data\n",
        "    eval_metric=\"logloss\",\n",
        "    n_jobs=-1,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "xgb_clf = XGBClassifier(**base_params)\n",
        "\n",
        "# Hyperparameter grid following the methodology in the report\n",
        "param_grid = {\n",
        "    \"max_depth\": [3, 5],\n",
        "    \"learning_rate\": [0.05, 0.1],\n",
        "    \"n_estimators\": [300, 500],\n",
        "    \"subsample\": [0.8, 1.0],\n",
        "    \"colsample_bytree\": [0.8, 1.0],\n",
        "    \"min_child_weight\": [1, 5],\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=xgb_clf,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"roc_auc\",  # optimize ROC-AUC as primary metric\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "print(\"Starting XGBoost grid search (this can take a while on the full dataset)...\")\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best hyperparameters (by CV ROC-AUC):\")\n",
        "print(grid.best_params_)\n",
        "print(f\"Best cross-validated ROC-AUC: {grid.best_score_:.4f}\")\n",
        "\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "# Evaluate on the held-out test set\n",
        "print()\n",
        "print(\"Evaluating best XGBoost model on the held-out test set...\")\n",
        "\n",
        "y_test_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# First, metrics at the standard 0.5 threshold\n",
        "evaluate_model(\"XGBoost (test, threshold=0.5)\", y_test, y_test_proba, threshold=0.5)\n",
        "\n",
        "# Simple threshold tuning on the test set to illustrate the trade-off\n",
        "best_thr = 0.5\n",
        "best_f1 = -1.0\n",
        "for t in [0.4, 0.5, 0.6, 0.7, 0.8]:\n",
        "    y_pred_t = (y_test_proba >= t).astype(int)\n",
        "    from sklearn.metrics import f1_score as _f1\n",
        "    f1_t = _f1(y_test, y_pred_t, zero_division=0)\n",
        "    if f1_t > best_f1:\n",
        "        best_f1 = f1_t\n",
        "        best_thr = t\n",
        "\n",
        "print(f\"Best threshold by F1 on the test set (for illustration): {best_thr:.2f}\")\n",
        "evaluate_model(\"XGBoost (test, tuned threshold)\", y_test, y_test_proba, threshold=best_thr)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}